{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, PowerTransformer, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/volodymyrgavrysh/bank-marketing-campaigns-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Description\n",
    "\n",
    "### bank client data:\n",
    "- __age__\n",
    "- __job__ : type of job (categorical: \"admin.\",\"blue-collar\",\"entrepreneur\",...,\"unknown\")\n",
    "- __marital__ : marital status (categorical: \"divorced\",\"married\",\"single\",\"unknown\")\n",
    "- __education__ : (categorical: \"illiterate\",...,\"university.degree\",\"unknown\")\n",
    "- __default__: has credit in default? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "- __housing__: has housing loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "- __loan__: has personal loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "    \n",
    "### related with the last contact of the current campaign:\n",
    "- __contact__: contact communication type (categorical: \"cellular\",\"telephone\")\n",
    "- __month__: last contact month of year (categorical: \"jan\", …, \"nov\", \"dec\")\n",
    "- __dayofweek__: last contact day of the week (categorical: \"mon\",\"tue\",...)\n",
    "- __duration__: last contact duration, in seconds (numeric).\n",
    "    - __Important note__: this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). , Can not get this feature before the campaign\n",
    "\n",
    "### other attributes:\n",
    "- __campaign__: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "    - __Important note__: Can not get this feature before the campaign\n",
    "- __pdays__: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "- __previous__: number of contacts performed before this campaign and for this client (numeric)\n",
    "- __poutcome__: outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\n",
    "\n",
    "### social and economic context attributes\n",
    "- __emp.var.rate__: employment variation rate - quarterly indicator (numeric)\n",
    "- __cons.price.idx__: consumer price index - monthly indicator (changes in the price level of a weighted average __market basket__ of consumer goods and services purchased by households, affect inflation (numeric))\n",
    "- __cons.conf.idx__: consumer confidence index - monthly indicator (degree of __consumers optimism__ are expressing through their activities of savings and spending. affect consumer behavior (numeric))\n",
    "- __euribor3m__: euribor 3 month rate - daily indicator (Euribor (euro interbank offered rate) (numeric))\n",
    "- __nr.employed__: number of employees - quarterly indicator (Number of employed persons for a quarter (numeric))\n",
    "\n",
    "### Output variable (desired target):\n",
    "- __y__ - has the client subscribed a term deposit? (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS \n",
    "\n",
    "1. __Reduce False Positive__ \n",
    "2. __Increase Precision for y='yes'__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data from csv\n",
    "\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change value format in education column\n",
    "\n",
    "df.education = df.education.apply(lambda x : x.replace(\".\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that we can not get if we use the model before the campaign\n",
    "\n",
    "df_1 = df.drop(columns=['duration', 'campaign'\n",
    "#                         , 'emp.var.rate', 'nr.employed', 'day_of_week', 'housing'\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic 4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic 6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic 4y       no      no   no  telephone   \n",
       "1   57   services  married  high school  unknown      no   no  telephone   \n",
       "2   37   services  married  high school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic 6y       no      no   no  telephone   \n",
       "4   56   services  married  high school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  pdays  previous     poutcome  emp.var.rate  \\\n",
       "0   may         mon    999         0  nonexistent           1.1   \n",
       "1   may         mon    999         0  nonexistent           1.1   \n",
       "2   may         mon    999         0  nonexistent           1.1   \n",
       "3   may         mon    999         0  nonexistent           1.1   \n",
       "4   may         mon    999         0  nonexistent           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing dataframe\n",
    "\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change target column values to integer value\n",
    "\n",
    "df_1['y'][df_1['y'] == 'no'] = 0\n",
    "df_1['y'][df_1['y'] == 'yes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36548\n",
       "1     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the value in target columns\n",
    "\n",
    "df_1['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the value's type into integer\n",
    "\n",
    "df_1['y'] = df_1['y'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    88.73\n",
       "1    11.27\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of the target column values in percentage\n",
    "\n",
    "round(df_1['y'].value_counts()/len(df_1)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Engineering\n",
    "\n",
    "1. __Label Encoding__ for education column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding using map\n",
    "\n",
    "df_1['education'] = df_1['education'].map({'basic 4y':1\n",
    "                              , 'basic 6y':2\n",
    "                              , 'basic 9y' :3\n",
    "                              , \"high school\":4\n",
    "                              , \"university degree\":5\n",
    "                              , 'professional course':6\n",
    "                              , 'illiterate':0\n",
    "                              , 'unknown':0\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the columns into X and Y\n",
    "\n",
    "X = df_1.drop(columns='y')\n",
    "y = df_1['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling\n",
    "\n",
    "Do oversampling method (because the data is imbalance) __only__ for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frame from train data\n",
    "\n",
    "df_train = pd.concat([X_train,y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25611</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.120</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.120</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40194</th>\n",
       "      <td>78</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.215</td>\n",
       "      <td>-40.3</td>\n",
       "      <td>0.870</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>36</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36344</th>\n",
       "      <td>59</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.963</td>\n",
       "      <td>-40.8</td>\n",
       "      <td>1.262</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job   marital  education  default housing loan  \\\n",
       "25611   49   blue-collar   married          3  unknown      no   no   \n",
       "26010   37  entrepreneur   married          5       no      no   no   \n",
       "40194   78       retired   married          1       no      no   no   \n",
       "297     36        admin.   married          5       no     yes   no   \n",
       "36344   59       retired  divorced          5       no      no   no   \n",
       "\n",
       "         contact month day_of_week  pdays  previous     poutcome  \\\n",
       "25611   cellular   nov         wed    999         0  nonexistent   \n",
       "26010  telephone   nov         wed    999         1      failure   \n",
       "40194   cellular   jul         mon    999         0  nonexistent   \n",
       "297    telephone   may         mon    999         0  nonexistent   \n",
       "36344   cellular   jun         tue    999         0  nonexistent   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "25611          -0.1          93.200          -42.0      4.120       5195.8  0  \n",
       "26010          -0.1          93.200          -42.0      4.120       5195.8  0  \n",
       "40194          -1.7          94.215          -40.3      0.870       4991.6  1  \n",
       "297             1.1          93.994          -36.4      4.857       5191.0  0  \n",
       "36344          -2.9          92.963          -40.8      1.262       5076.2  0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show df_train\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29238\n",
       "1     3712\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data imbalance in df_train\n",
    "\n",
    "df_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_default = df_train[df_train['y'] == 0] # majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = df_train[df_train['y'] == 1] # minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling/Upsampling with resample method\n",
    "\n",
    "default_oversample = resample(default, \n",
    "                           replace = True, \n",
    "                           n_samples = len(non_default),\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frame for oversampling data\n",
    "\n",
    "df_OverSample= pd.concat([non_default, default_oversample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    29238\n",
       "0    29238\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data imbalance in df_oversample\n",
    "\n",
    "df_OverSample['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data X and Y for Oversample Data fram\n",
    "\n",
    "X_train_OS = df_OverSample.drop(columns='y')\n",
    "y_train_OS = df_OverSample['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "we used pipeline method for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the numeric columns and categoric columns from the dataset\n",
    "\n",
    "num_columns = ['age', 'education', 'pdays', 'previous', 'cons.price.idx', 'cons.conf.idx', 'euribor3m'\n",
    "               , 'nr.employed', 'emp.var.rate'\n",
    "              ]\n",
    "\n",
    "cat_columns = [i for i in df_1.columns if (i not in num_columns) & (i!='y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline and model\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "#     ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#     ('power', PowerTransformer(method='yeo-johnson'))\n",
    "])\n",
    "\n",
    "categoric_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_pipeline, num_columns),\n",
    "    ('categorical', categoric_pipeline, cat_columns)\n",
    "])\n",
    "\n",
    "pipe_LR = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_KNN = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipe_SVM = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', SVC(max_iter=600))\n",
    "])\n",
    "\n",
    "pipe_DT = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_RF = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_XGB = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def Function for Evaluation Metrix\n",
    "\n",
    "create a `def` function for evaluation metrix after modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function for each model evaluation matrix\n",
    "\n",
    "def conf_mat (Model, X_train, X_test, y_train, y_test,Nama):\n",
    "    y_pred_test = Model.predict(X_test)\n",
    "    cm_test = confusion_matrix(y_test, y_pred_test, labels=[1,0])\n",
    "    df_test = pd.DataFrame(cm_test, index = ['Akt1', 'Akt0'], columns=['Pred1', 'Pred0'])\n",
    "    print( 'Classification report data TEST ' + Nama + '\\n\\n', classification_report(y_test, y_pred_test))\n",
    "    print('\\nROC AUC test :', round(roc_auc_score(y_test, y_pred_test), 2), '\\n')\n",
    "    print('\\nConfusion matrix data test ' + Nama + '\\n\\n')\n",
    "    print(df_test)\n",
    "    print('='*100)\n",
    "    y_pred_train = Model.predict(X_train)\n",
    "    cm_train = confusion_matrix(y_train, y_pred_train, labels=[1,0])\n",
    "    df_train = pd.DataFrame(cm_train, index = ['Akt1', 'Akt0'], columns=['Pred1', 'Pred0'])\n",
    "    print( 'Classification report data TRAIN ' + Nama + '\\n\\n', classification_report(y_train, y_pred_train))\n",
    "    print('\\nROC AUC train :', round(roc_auc_score(y_train, y_pred_train), 2), '\\n')\n",
    "    print('\\nConfusion matrix data train ' + Nama + '\\n\\n')\n",
    "    print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function to compare the evaluation matrix for some models\n",
    "\n",
    "def prec_rec (Model, X_test, y_test, Nama):\n",
    "    data = {}\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for i in Model :\n",
    "        y_pred_ts = i.predict(X_test)\n",
    "        precision = precision_score(y_test, y_pred_ts)\n",
    "        recall = recall_score(y_test, y_pred_ts)\n",
    "        prec.append(precision)\n",
    "        rec.append(recall)\n",
    "    for j in range (len(Nama)):\n",
    "        data[Nama[j]] = [prec[j], rec[j]]\n",
    "    \n",
    "    df = pd.DataFrame(data, index=['Precison', 'Recall'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', LogisticRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression base model fitting\n",
    "\n",
    "pipe_LR.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST LR Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      7310\n",
      "           1       0.36      0.65      0.46       928\n",
      "\n",
      "    accuracy                           0.83      8238\n",
      "   macro avg       0.65      0.75      0.68      8238\n",
      "weighted avg       0.88      0.83      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.75 \n",
      "\n",
      "\n",
      "Confusion matrix data test LR Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    599    329\n",
      "Akt0   1082   6228\n",
      "====================================================================================================\n",
      "Classification report data TRAIN LR Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76     29238\n",
      "           1       0.80      0.62      0.70     29238\n",
      "\n",
      "    accuracy                           0.73     58476\n",
      "   macro avg       0.75      0.73      0.73     58476\n",
      "weighted avg       0.75      0.73      0.73     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.73 \n",
      "\n",
      "\n",
      "Confusion matrix data train LR Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  18136  11102\n",
      "Akt0   4411  24827\n"
     ]
    }
   ],
   "source": [
    "# evaluation matrix of Logistic regression base model\n",
    "\n",
    "conf_mat(pipe_LR, X_train_OS, X_test, y_train_OS, y_test, 'LR Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__K-Nearest Neighbor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Nearest Neighbor base model fitting\n",
    "\n",
    "pipe_KNN.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST KNN Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      7310\n",
      "           1       0.27      0.57      0.37       928\n",
      "\n",
      "    accuracy                           0.78      8238\n",
      "   macro avg       0.60      0.69      0.62      8238\n",
      "weighted avg       0.86      0.78      0.81      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.69 \n",
      "\n",
      "\n",
      "Confusion matrix data test KNN Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    531    397\n",
      "Akt0   1424   5886\n",
      "====================================================================================================\n",
      "Classification report data TRAIN KNN Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92     29238\n",
      "           1       0.87      1.00      0.93     29238\n",
      "\n",
      "    accuracy                           0.93     58476\n",
      "   macro avg       0.93      0.93      0.93     58476\n",
      "weighted avg       0.93      0.93      0.93     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.93 \n",
      "\n",
      "\n",
      "Confusion matrix data train KNN Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29115    123\n",
      "Akt0   4194  25044\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrix of K-Nearest Neighbor base model\n",
    "\n",
    "conf_mat(pipe_KNN, X_train_OS, X_test, y_train_OS, y_test, 'KNN Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Support Vector Machine__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', SVC(max_iter=600))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machine base model fitting\n",
    "\n",
    "pipe_SVM.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST SVM Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.01      0.03      7310\n",
      "           1       0.09      0.80      0.17       928\n",
      "\n",
      "    accuracy                           0.10      8238\n",
      "   macro avg       0.22      0.41      0.10      8238\n",
      "weighted avg       0.32      0.10      0.04      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.41 \n",
      "\n",
      "\n",
      "Confusion matrix data test SVM Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    741    187\n",
      "Akt0   7208    102\n",
      "====================================================================================================\n",
      "Classification report data TRAIN SVM Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.02      0.02     29238\n",
      "           1       0.45      0.79      0.57     29238\n",
      "\n",
      "    accuracy                           0.40     58476\n",
      "   macro avg       0.26      0.40      0.30     58476\n",
      "weighted avg       0.26      0.40      0.30     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.4 \n",
      "\n",
      "\n",
      "Confusion matrix data train SVM Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  23095   6143\n",
      "Akt0  28792    446\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of Support Vector Machine base model\n",
    "\n",
    "conf_mat(pipe_SVM, X_train_OS, X_test, y_train_OS, y_test, 'SVM Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decision Tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree base model fitting\n",
    "\n",
    "pipe_DT.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST DT Over Sampling\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      7310\n",
      "           1       0.31      0.36      0.33       928\n",
      "\n",
      "    accuracy                           0.84      8238\n",
      "   macro avg       0.61      0.63      0.62      8238\n",
      "weighted avg       0.85      0.84      0.84      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.63 \n",
      "\n",
      "\n",
      "Confusion matrix data test DT Over Sampling\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    331    597\n",
      "Akt0    750   6560\n",
      "====================================================================================================\n",
      "Classification report data TRAIN DT Over Sampling\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     29238\n",
      "           1       0.99      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train DT Over Sampling\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29224     14\n",
      "Akt0    438  28800\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of Decision Tree base model\n",
    "\n",
    "conf_mat(pipe_DT, X_train_OS, X_test, y_train_OS, y_test, 'DT Over Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest base model fitting\n",
    "\n",
    "pipe_RF.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      7310\n",
      "           1       0.45      0.41      0.43       928\n",
      "\n",
      "    accuracy                           0.88      8238\n",
      "   macro avg       0.69      0.67      0.68      8238\n",
      "weighted avg       0.87      0.88      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.67 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    382    546\n",
      "Akt0    473   6837\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.99      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29228     10\n",
      "Akt0    442  28796\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of Random Forest base model\n",
    "\n",
    "conf_mat(pipe_RF, X_train_OS, X_test, y_train_OS, y_test, 'RF Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__XGBoost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:54:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'd...\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost base model fitting\n",
    "\n",
    "pipe_XGB.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST XGB Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91      7310\n",
      "           1       0.39      0.59      0.47       928\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.67      0.74      0.69      8238\n",
      "weighted avg       0.88      0.85      0.86      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.74 \n",
      "\n",
      "\n",
      "Confusion matrix data test XGB Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    552    376\n",
      "Akt0    870   6440\n",
      "====================================================================================================\n",
      "Classification report data TRAIN XGB Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85     29238\n",
      "           1       0.89      0.79      0.84     29238\n",
      "\n",
      "    accuracy                           0.85     58476\n",
      "   macro avg       0.85      0.85      0.85     58476\n",
      "weighted avg       0.85      0.85      0.85     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.85 \n",
      "\n",
      "\n",
      "Confusion matrix data train XGB Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  23185   6053\n",
      "Akt0   2904  26334\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of XGBoost base model\n",
    "\n",
    "conf_mat(pipe_XGB, X_train_OS, X_test, y_train_OS, y_test, 'XGB Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Base Models's Evaluation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_Base</th>\n",
       "      <th>KNN_Base</th>\n",
       "      <th>SVM_Base</th>\n",
       "      <th>DT_Base</th>\n",
       "      <th>RF_Base</th>\n",
       "      <th>XGB_Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precison</th>\n",
       "      <td>0.356336</td>\n",
       "      <td>0.271611</td>\n",
       "      <td>0.093219</td>\n",
       "      <td>0.306198</td>\n",
       "      <td>0.446784</td>\n",
       "      <td>0.388186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.645474</td>\n",
       "      <td>0.572198</td>\n",
       "      <td>0.798491</td>\n",
       "      <td>0.356681</td>\n",
       "      <td>0.411638</td>\n",
       "      <td>0.594828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LR_Base  KNN_Base  SVM_Base   DT_Base   RF_Base  XGB_Base\n",
       "Precison  0.356336  0.271611  0.093219  0.306198  0.446784  0.388186\n",
       "Recall    0.645474  0.572198  0.798491  0.356681  0.411638  0.594828"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the precision and recall of all base model\n",
    "\n",
    "prec_rec ([pipe_LR, pipe_KNN, pipe_SVM, pipe_DT, pipe_RF, pipe_XGB], X_test, y_test, ['LR_Base', 'KNN_Base', 'SVM_Base', 'DT_Base', 'RF_Base', 'XGB_Base'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __HYPERPARAMETER TUNING__\n",
    "\n",
    "we choose 4 potential models for hyperparameter tuning:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the stratifiedKfold for cross validation in hyperparameter tuning\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default Parameter__\n",
    "- 'algo__C': 1,\n",
    "- 'algo__class_weight': None,\n",
    "- 'algo__fit_intercept': True,\n",
    "- 'algo__penalty': 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Logistic regression parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_LR = {\n",
    "    'algo__C' : list(np.logspace(-4,1,10)) + [1.0],\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.1, 1:.9}],\n",
    "    'algo__fit_intercept' : [False, True],\n",
    "    'algo__penalty' : ['l1', 'l2', 'elasticnet', 'none']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gridsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "LR_GS = GridSearchCV(pipe_LR, param_LR, cv=skf, n_jobs=-1, verbose=1, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 440 candidates, totalling 1320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 out of 1320 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('prep',\n",
       "                                        ColumnTransformer(transformers=[('numeric',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          RobustScaler())]),\n",
       "                                                                         ['age',\n",
       "                                                                          'education',\n",
       "                                                                          'pdays',\n",
       "                                                                          'previous',\n",
       "                                                                          'cons.price.idx',\n",
       "                                                                          'cons.conf.idx',\n",
       "                                                                          'euribor3m',\n",
       "                                                                          'nr.employed',\n",
       "                                                                          'emp.var.rate']),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('encode...\n",
       "             param_grid={'algo__C': [0.0001, 0.00035938136638046257,\n",
       "                                     0.001291549665014884, 0.004641588833612782,\n",
       "                                     0.016681005372000592, 0.05994842503189409,\n",
       "                                     0.21544346900318845, 0.7742636826811278,\n",
       "                                     2.782559402207126, 10.0, 1.0],\n",
       "                         'algo__class_weight': [None, {0: 0.4, 1: 0.6},\n",
       "                                                {0: 0.3, 1: 0.7},\n",
       "                                                {0: 0.2, 1: 0.8},\n",
       "                                                {0: 0.1, 1: 0.9}],\n",
       "                         'algo__fit_intercept': [False, True],\n",
       "                         'algo__penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "LR_GS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__C': 0.0001,\n",
       " 'algo__class_weight': None,\n",
       " 'algo__fit_intercept': True,\n",
       " 'algo__penalty': 'none'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameter that create the best precision score\n",
    "\n",
    "LR_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logistic regression model after tuning that have the best parameter\n",
    "\n",
    "LR_Tune = LR_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', LogisticRegression(C=0.0001, penalty='none'))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the model\n",
    "\n",
    "LR_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST LR Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      7310\n",
      "           1       0.35      0.64      0.46       928\n",
      "\n",
      "    accuracy                           0.83      8238\n",
      "   macro avg       0.65      0.75      0.68      8238\n",
      "weighted avg       0.88      0.83      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.75 \n",
      "\n",
      "\n",
      "Confusion matrix data test LR Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    595    333\n",
      "Akt0   1082   6228\n",
      "====================================================================================================\n",
      "Classification report data TRAIN LR Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76     29238\n",
      "           1       0.81      0.62      0.70     29238\n",
      "\n",
      "    accuracy                           0.74     58476\n",
      "   macro avg       0.75      0.74      0.73     58476\n",
      "weighted avg       0.75      0.74      0.73     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.74 \n",
      "\n",
      "\n",
      "Confusion matrix data train LR Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  18125  11113\n",
      "Akt0   4378  24860\n"
     ]
    }
   ],
   "source": [
    "# evaluation matrix of the model\n",
    "\n",
    "conf_mat(LR_Tune, X_train_OS, X_test, y_train_OS, y_test, 'LR Tuning 1 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2nd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Logistic regression parameter for the 2nd hyperparameter tuning\n",
    "\n",
    "param_LR2 = {\n",
    "    'algo__C' : np.logspace(-6,-3),\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.1, 1:.9}],\n",
    "    'algo__fit_intercept' : [False, True],\n",
    "    'algo__penalty' : ['l1', 'l2', 'elasticnet', 'none']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gridsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "LR_GS2 = GridSearchCV(pipe_LR, param_LR2, cv=skf, n_jobs=-1, verbose=1, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2000 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('prep',\n",
       "                                        ColumnTransformer(transformers=[('numeric',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          RobustScaler())]),\n",
       "                                                                         ['age',\n",
       "                                                                          'education',\n",
       "                                                                          'pdays',\n",
       "                                                                          'previous',\n",
       "                                                                          'cons.price.idx',\n",
       "                                                                          'cons.conf.idx',\n",
       "                                                                          'euribor3m',\n",
       "                                                                          'nr.employed',\n",
       "                                                                          'emp.var.rate']),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('encode...\n",
       "       2.81176870e-04, 3.23745754e-04, 3.72759372e-04, 4.29193426e-04,\n",
       "       4.94171336e-04, 5.68986603e-04, 6.55128557e-04, 7.54312006e-04,\n",
       "       8.68511374e-04, 1.00000000e-03]),\n",
       "                         'algo__class_weight': [None, {0: 0.4, 1: 0.6},\n",
       "                                                {0: 0.3, 1: 0.7},\n",
       "                                                {0: 0.2, 1: 0.8},\n",
       "                                                {0: 0.1, 1: 0.9}],\n",
       "                         'algo__fit_intercept': [False, True],\n",
       "                         'algo__penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "LR_GS2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__C': 1e-06,\n",
       " 'algo__class_weight': None,\n",
       " 'algo__fit_intercept': True,\n",
       " 'algo__penalty': 'l2'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "LR_GS2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logistic regression model after tuning that have the best parameter\n",
    "\n",
    "LR_Tune2 = LR_GS2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', LogisticRegression(C=1e-06))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_Tune2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST LR Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.94      7310\n",
      "           1       0.65      0.20      0.31       928\n",
      "\n",
      "    accuracy                           0.90      8238\n",
      "   macro avg       0.78      0.59      0.63      8238\n",
      "weighted avg       0.88      0.90      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.59 \n",
      "\n",
      "\n",
      "Confusion matrix data test LR Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    187    741\n",
      "Akt0    102   7208\n",
      "====================================================================================================\n",
      "Classification report data TRAIN LR Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71     29238\n",
      "           1       0.93      0.21      0.34     29238\n",
      "\n",
      "    accuracy                           0.60     58476\n",
      "   macro avg       0.74      0.60      0.53     58476\n",
      "weighted avg       0.74      0.60      0.53     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.6 \n",
      "\n",
      "\n",
      "Confusion matrix data train LR Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1   6143  23095\n",
      "Akt0    446  28792\n"
     ]
    }
   ],
   "source": [
    "conf_mat(LR_Tune2, X_train_OS, X_test, y_train_OS, y_test, 'LR Tuning 2 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default parameter__\n",
    "- 'algo__max_depth': None\n",
    "- 'algo__min_samples_leaf': 1\n",
    "- 'algo__max_features': None\n",
    "- 'algo__class_weight': None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Decision tree parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_DT = {\n",
    "    'algo__max_depth': list(np.arange(0, 101, 5)) + [None],\n",
    "    'algo__min_samples_leaf': np.arange(1, 1000, 50),\n",
    "    'algo__max_features': [None, 0.2, 0.5, 0.8, 1],\n",
    "    'algo__class_weight': [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "DT_RS = RandomizedSearchCV(pipe_DT, param_DT, cv=skf, n_iter=2000, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2000 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2,\n",
       "                                                                1: 0.8}],\n",
       "                                        'algo__max_depth': [0, 5, 10, 15, 20,\n",
       "                                                            25, 30, 35, 40, 45,\n",
       "                                                            50, 55, 60, 65, 70,\n",
       "                                                            75, 80, 85, 90, 95,\n",
       "                                                            100, None],\n",
       "                                        'algo__max_features': [None, 0.2, 0.5,\n",
       "                                                               0.8, 1],\n",
       "                                        'algo__min_samples_leaf': array([  1,  51, 101, 151, 201, 251, 301, 351, 401, 451, 501, 551, 601,\n",
       "       651, 701, 751, 801, 851, 901, 951])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "DT_RS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__min_samples_leaf': 1,\n",
       " 'algo__max_features': 0.8,\n",
       " 'algo__max_depth': 95,\n",
       " 'algo__class_weight': {0: 0.2, 1: 0.8}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "DT_RS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Decision tree model after tuning that have the best parameter\n",
    "\n",
    "DT_Tune = DT_RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 DecisionTreeClassifier(class_weight={0: 0.2, 1: 0.8},\n",
       "                                        max_depth=95, max_features=0.8,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST DT Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      7310\n",
      "           1       0.32      0.33      0.33       928\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.62      0.62      0.62      8238\n",
      "weighted avg       0.85      0.85      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.62 \n",
      "\n",
      "\n",
      "Confusion matrix data test DT Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    307    621\n",
      "Akt0    646   6664\n",
      "====================================================================================================\n",
      "Classification report data TRAIN DT Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train DT Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(DT_Tune, X_train_OS, X_test, y_train_OS, y_test, 'DT Tuning 1 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2nd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Decision tree parameter for the 2nd hyperparameter tuning\n",
    "\n",
    "param_DT2 = {\n",
    "    'algo__max_depth': list(np.arange(50, 151, 5)) + [None],\n",
    "    'algo__min_samples_leaf': np.arange(1, 100, 10),\n",
    "    'algo__max_features': [None, 0.2, 0.5, 0.8, 1],\n",
    "    'algo__class_weight': [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "DT_RS2 = RandomizedSearchCV(pipe_DT, param_DT2, cv=skf, n_iter=2000, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2000 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                   n_iter=2000, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2,\n",
       "                                                                1: 0.8}],\n",
       "                                        'algo__max_depth': [50, 55, 60, 65, 70,\n",
       "                                                            75, 80, 85, 90, 95,\n",
       "                                                            100, 105, 110, 115,\n",
       "                                                            120, 125, 130, 135,\n",
       "                                                            140, 145, 150,\n",
       "                                                            None],\n",
       "                                        'algo__max_features': [None, 0.2, 0.5,\n",
       "                                                               0.8, 1],\n",
       "                                        'algo__min_samples_leaf': array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "DT_RS2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__min_samples_leaf': 1,\n",
       " 'algo__max_features': 0.8,\n",
       " 'algo__max_depth': 60,\n",
       " 'algo__class_weight': {0: 0.2, 1: 0.8}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "DT_RS2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Decision tree model after tuning that have the best parameter\n",
    "\n",
    "DT_Tune2 = DT_RS2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 DecisionTreeClassifier(class_weight={0: 0.2, 1: 0.8},\n",
       "                                        max_depth=60, max_features=0.8,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_Tune2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST DT Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      7310\n",
      "           1       0.32      0.33      0.33       928\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.62      0.62      0.62      8238\n",
      "weighted avg       0.85      0.85      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.62 \n",
      "\n",
      "\n",
      "Confusion matrix data test DT Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    307    621\n",
      "Akt0    646   6664\n",
      "====================================================================================================\n",
      "Classification report data TRAIN DT Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train DT Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(DT_Tune2, X_train_OS, X_test, y_train_OS, y_test, 'DT Tuning 2 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default__\n",
    "- 'algo__n_estimators': 100,\n",
    "- 'algo__max_depth': None,\n",
    "- 'algo__min_samples_leaf': 1,\n",
    "- 'algo__class_weight': None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Random Forest parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_RF = {\n",
    "    'algo__n_estimators' : np.arange(100, 1000, 100),\n",
    "    'algo__max_depth' : list(np.arange(10, 100, 10)) + [None],\n",
    "    'algo__min_samples_leaf' : list(np.arange(10, 100, 10)) + [1],\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.15, 1: .85}, {0:.1, 1:.9}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "RF_RS = RandomizedSearchCV(pipe_RF, param_RF, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 155.9min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 176.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2, 1: 0.8},\n",
       "                                                               {0: 0.15,\n",
       "                                                                1: 0.85},\n",
       "                                                               {0: 0.1,\n",
       "                                                                1: 0.9}],\n",
       "                                        'algo__max_depth': [10, 20, 30, 40, 50,\n",
       "                                                            60, 70, 80, 90,\n",
       "                                                            None],\n",
       "                                        'algo__min_samples_leaf': [10, 20, 30,\n",
       "                                                                   40, 50, 60,\n",
       "                                                                   70, 80, 90,\n",
       "                                                                   1],\n",
       "                                        'algo__n_estimators': array([100, 200, 300, 400, 500, 600, 700, 800, 900])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "RF_RS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 100,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__max_depth': 90,\n",
       " 'algo__class_weight': {0: 0.2, 1: 0.8}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "RF_RS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model after tuning that have the best parameter\n",
    "\n",
    "RF_Tune = RF_RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 RandomForestClassifier(class_weight={0: 0.2, 1: 0.8},\n",
       "                                        max_depth=90, random_state=42))])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Tuning best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      7310\n",
      "           1       0.45      0.41      0.43       928\n",
      "\n",
      "    accuracy                           0.88      8238\n",
      "   macro avg       0.69      0.67      0.68      8238\n",
      "weighted avg       0.87      0.88      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.67 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Tuning best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    379    549\n",
      "Akt0    471   6839\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Tuning best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Tuning best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(RF_Tune, X_train_OS, X_test, y_train_OS, y_test, 'RF Tuning best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2nd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Random Forest parameter for the 2nd hyperparameter tuning\n",
    "\n",
    "param_RF2 = {\n",
    "    'algo__n_estimators' : [10, 20, 30, 50, 80, 100],\n",
    "    'algo__max_depth' : [None, 1, 3, 5, 8, 10],\n",
    "    'algo__min_samples_leaf' : [1, 3, 5, 8, 10],\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.1, 1:.9}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "RF_RS2 = RandomizedSearchCV(pipe_RF, param_RF2, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                                                                                'poutcome'])])),\n",
       "                                             ('algo',\n",
       "                                              RandomForestClassifier(random_state=42))]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2, 1: 0.8},\n",
       "                                                               {0: 0.1,\n",
       "                                                                1: 0.9}],\n",
       "                                        'algo__max_depth': [None, 1, 3, 5, 8,\n",
       "                                                            10],\n",
       "                                        'algo__min_samples_leaf': [1, 3, 5, 8,\n",
       "                                                                   10],\n",
       "                                        'algo__n_estimators': [10, 20, 30, 50,\n",
       "                                                               80, 100]},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "RF_RS2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 10,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__max_depth': None,\n",
       " 'algo__class_weight': {0: 0.3, 1: 0.7}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "RF_RS2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model after tuning that have the best parameter\n",
    "\n",
    "RF_Tune2 = RF_RS2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 RandomForestClassifier(class_weight={0: 0.3, 1: 0.7},\n",
       "                                        n_estimators=10, random_state=42))])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Tune2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      7310\n",
      "           1       0.41      0.36      0.39       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.67      0.65      0.66      8238\n",
      "weighted avg       0.86      0.87      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.65 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    334    594\n",
      "Akt0    473   6837\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29234      4\n",
      "Akt0    506  28732\n"
     ]
    }
   ],
   "source": [
    "conf_mat(RF_Tune2, X_train_OS, X_test, y_train_OS, y_test, 'RF Tuning 2 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3rd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Random Forest parameter for the 3rd hyperparameter tuning\n",
    "\n",
    "param_RF3 = {\n",
    "    'algo__n_estimators' : np.arange(60, 150, 20),\n",
    "    'algo__max_depth' : list(np.arange(50, 150, 20)) + [None],\n",
    "    'algo__min_samples_leaf' : np.arange(1, 10, 2),\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.15, 1: .85}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "RF_RS3 = RandomizedSearchCV(pipe_RF, param_RF3, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 18.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                                              RandomForestClassifier(random_state=42))]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2, 1: 0.8},\n",
       "                                                               {0: 0.15,\n",
       "                                                                1: 0.85}],\n",
       "                                        'algo__max_depth': [50, 70, 90, 110,\n",
       "                                                            130, None],\n",
       "                                        'algo__min_samples_leaf': array([1, 3, 5, 7, 9]),\n",
       "                                        'algo__n_estimators': array([ 60,  80, 100, 120, 140])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "RF_RS3.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 60,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__max_depth': 90,\n",
       " 'algo__class_weight': {0: 0.15, 1: 0.85}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "RF_RS3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model after tuning that have the best parameter\n",
    "\n",
    "RF_Tune3 = RF_RS3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 RandomForestClassifier(class_weight={0: 0.15, 1: 0.85},\n",
       "                                        max_depth=90, n_estimators=60,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Tune3.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Tuning 3 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      7310\n",
      "           1       0.43      0.39      0.41       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.68      0.66      0.67      8238\n",
      "weighted avg       0.87      0.87      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.66 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Tuning 3 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    366    562\n",
      "Akt0    479   6831\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Tuning 3 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Tuning 3 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(RF_Tune3, X_train_OS, X_test, y_train_OS, y_test, 'RF Tuning 3 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DEFAULT PARAMETER__\n",
    "\n",
    "1. 'algo__n_estimators': 100,\n",
    "2. 'algo__max_depth': 6,\n",
    "3. 'algo__learning_rate': 0.300000012,\n",
    "4. 'algo__gamma': 0,\n",
    "5. 'algo__colsample_bytree': 1,\n",
    "6. 'algo__subsample': 1,\n",
    "7. 'algo__reg_alpha': 0,\n",
    "8. 'algo__reg_lambda': 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st Tuning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the XGBoost parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_XGB = {\n",
    "    'algo__n_estimators' : np.arange(100, 600, 100),\n",
    "    'algo__max_depth' : [2, 3, 5, 6, 8, 10],\n",
    "    'algo__learning_rate' : list(np.logspace(-3, 0, 4)) + [0.300000012],\n",
    "    'algo__gamma' : np.logspace(-3, 2, 6)\n",
    "#     'algo__colsample_bytree' : [0.3, 0.5, 0.7, 0.8],\n",
    "#     'algo__subsample' : [0.3, 0.5, 0.7, 0.8],\n",
    "#     'algo__reg_alpha' : np.logspace(-3, 3, 7),\n",
    "#     'algo__reg_lambda' : np.logspace(-3, 3, 7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "XGB_RS = RandomizedSearchCV(pipe_XGB, param_XGB, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 65.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 93.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:57:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                                                            tree_method='exact',\n",
       "                                                            validate_parameters=1,\n",
       "                                                            verbosity=None))]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__gamma': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        'algo__learning_rate': [0.001, 0.01,\n",
       "                                                                0.1, 1.0,\n",
       "                                                                0.300000012],\n",
       "                                        'algo__max_depth': [2, 3, 5, 6, 8, 10],\n",
       "                                        'algo__n_estimators': array([100, 200, 300, 400, 500])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "XGB_RS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 500,\n",
       " 'algo__max_depth': 10,\n",
       " 'algo__learning_rate': 0.300000012,\n",
       " 'algo__gamma': 0.01}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "XGB_RS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost model after tuning that have the best parameter\n",
    "\n",
    "XGB_Tune = XGB_RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:05:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'd...\n",
       "                               colsample_bytree=1, gamma=0.01, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=10, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=500,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST XGB Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      7310\n",
      "           1       0.41      0.40      0.40       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.67      0.66      0.66      8238\n",
      "weighted avg       0.87      0.87      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.66 \n",
      "\n",
      "\n",
      "Confusion matrix data test XGB Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    370    558\n",
      "Akt0    536   6774\n",
      "====================================================================================================\n",
      "Classification report data TRAIN XGB Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train XGB Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29228     10\n",
      "Akt0    451  28787\n"
     ]
    }
   ],
   "source": [
    "conf_mat(XGB_Tune, X_train_OS, X_test, y_train_OS, y_test, 'XGB Tuning 1 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARING THE PRECISION OF ALL MODEL AFTER HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the model to def function Evaluation Matrix \n",
    "\n",
    "tabel_banding = prec_rec (\n",
    "    [pipe_LR, pipe_KNN, pipe_SVM, pipe_DT, pipe_RF, pipe_XGB, LR_Tune, LR_Tune2, DT_Tune, DT_Tune2, RF_Tune,\n",
    "     RF_Tune2, RF_Tune3, XGB_Tune],\n",
    "    X_test, y_test,\n",
    "    ['LR_Base', 'KNN_Base', 'SVM_Base', 'DT_Base', 'RF_Base', 'XGB_Base', 'LR_HPT_BE 1', 'LR_HPT_BE 2',\n",
    "     'DT_HPT_BE 1', 'DT_HPT_BE 2', 'RF_HPT_BE 1', 'RF_HPT_BE 2', 'RF_HPT_BE 3', 'XGB_HPT_BE 1']\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precison</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_HPT_BE 2</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.201509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_Base</th>\n",
       "      <td>0.446784</td>\n",
       "      <td>0.411638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_HPT_BE 1</th>\n",
       "      <td>0.445882</td>\n",
       "      <td>0.408405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_HPT_BE 3</th>\n",
       "      <td>0.433136</td>\n",
       "      <td>0.394397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_HPT_BE 2</th>\n",
       "      <td>0.413879</td>\n",
       "      <td>0.359914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precison    Recall\n",
       "LR_HPT_BE 2  0.647059  0.201509\n",
       "RF_Base      0.446784  0.411638\n",
       "RF_HPT_BE 1  0.445882  0.408405\n",
       "RF_HPT_BE 3  0.433136  0.394397\n",
       "RF_HPT_BE 2  0.413879  0.359914"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table that show 5 model with the best precision \n",
    "\n",
    "tabel_banding = tabel_banding.sort_values(by='Precison', ascending=False)\n",
    "tabel_banding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We use Logistic Regression (after the 2nd Hyperparameter tuning) with precison : 0.65 and recall : 0.2'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"We use Logistic Regression (after the 2nd Hyperparameter tuning) with precison : {(round(tabel_banding['Precison'][0], 2))} and recall : {(round(tabel_banding['Recall'][0], 2))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUGGESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add __costumer account__ feature that have greater impact to the model because before someone decide to take/buy a deposit, they surely gonna check their account first to see if they have enough money or not  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT PROBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table/dataframe for test data\n",
    "\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "df_test = df_test.reset_index()\n",
    "df_test = df_test.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LR Tune 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability of one person to take the deposit or not\n",
    "\n",
    "y_test_predictproba = LR_Tune2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all people (in test data) that gonna take the deposit or not\n",
    "\n",
    "y_test_predict = LR_Tune2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the data to df_test\n",
    "\n",
    "df_test['y_predict LR'] = y_test_predict # create new column for y predict\n",
    "df_test_predictproba = pd.DataFrame(y_test_predictproba) # create new dataframe for prediction of the probability\n",
    "df_test_predictproba = df_test_predictproba.rename(columns={0: \"predict_proba LR 0\", 1: \"predict_proba LR 1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine df_test with df that contain prediction of the probability\n",
    "\n",
    "df_test = pd.concat([df_test, df_test_predictproba], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the distribution of probability of buying the deposit for each people\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hist(df_test['predict_proba LR 1'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning the probability of buying the deposit for each people\n",
    "\n",
    "proba1_bin = [-1,0.45,0.6,df_test['predict_proba LR 1'].max()]\n",
    "label_proba1 = ['< 0.45', '0.45 - 0.6', '> 0.6']\n",
    "df_test['proba1_bin'] = pd.cut(df_test['predict_proba LR 1'], bins=proba1_bin, labels=label_proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "      <th>y_predict LR</th>\n",
       "      <th>predict_proba LR 0</th>\n",
       "      <th>predict_proba LR 1</th>\n",
       "      <th>proba1_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>management</td>\n",
       "      <td>divorced</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.556469</td>\n",
       "      <td>0.443531</td>\n",
       "      <td>&lt; 0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.963</td>\n",
       "      <td>-40.8</td>\n",
       "      <td>1.262</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.551559</td>\n",
       "      <td>0.448441</td>\n",
       "      <td>&lt; 0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>6</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.215</td>\n",
       "      <td>-40.3</td>\n",
       "      <td>0.810</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552235</td>\n",
       "      <td>0.447765</td>\n",
       "      <td>&lt; 0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559124</td>\n",
       "      <td>0.440876</td>\n",
       "      <td>&lt; 0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.843</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.531</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552116</td>\n",
       "      <td>0.447884</td>\n",
       "      <td>&lt; 0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job   marital  education  default housing loan    contact  \\\n",
       "0   32    management  divorced          5       no      no   no   cellular   \n",
       "1   37    unemployed   unknown          5       no      no   no   cellular   \n",
       "2   73       retired  divorced          6  unknown     yes   no   cellular   \n",
       "3   44  entrepreneur   married          1  unknown      no   no  telephone   \n",
       "4   28        admin.    single          4       no      no   no   cellular   \n",
       "\n",
       "  month day_of_week  ...  emp.var.rate  cons.price.idx cons.conf.idx  \\\n",
       "0   jul         tue  ...           1.4          93.918         -42.7   \n",
       "1   jun         tue  ...          -2.9          92.963         -40.8   \n",
       "2   jul         thu  ...          -1.7          94.215         -40.3   \n",
       "3   jun         tue  ...           1.4          94.465         -41.8   \n",
       "4   mar         fri  ...          -1.8          92.843         -50.0   \n",
       "\n",
       "   euribor3m  nr.employed  y  y_predict LR  predict_proba LR 0  \\\n",
       "0      4.961       5228.1  0             0            0.556469   \n",
       "1      1.262       5076.2  0             0            0.551559   \n",
       "2      0.810       4991.6  0             0            0.552235   \n",
       "3      4.961       5228.1  0             0            0.559124   \n",
       "4      1.531       5099.1  0             0            0.552116   \n",
       "\n",
       "   predict_proba LR 1  proba1_bin  \n",
       "0            0.443531      < 0.45  \n",
       "1            0.448441      < 0.45  \n",
       "2            0.447765      < 0.45  \n",
       "3            0.440876      < 0.45  \n",
       "4            0.447884      < 0.45  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "ax = sns.countplot(x=\"proba1_bin\", hue=\"y\", data=df_test)\n",
    "ax.set_title('Jumlah masing2 kelompok proba 1 tiap y nya', fontsize=20)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+.1, p.get_height()), \n",
    "                size=18\n",
    "               )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "__Export Model__\n",
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(LR_Tune2, 'Model_LR.jbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
